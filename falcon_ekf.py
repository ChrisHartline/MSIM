# -*- coding: utf-8 -*-
"""FALCON_EKF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JAnpP4ISLCK1EcVFrLIERe-pOVpUid9y
"""

# ============================================================================
# Day 2: Python EKF Prototype
# MSIM815 Final Project - Extended Kalman Filter Implementation
# ============================================================================

"""
PURPOSE: Implement and validate EKF in Python before C++ conversion
OUTPUTS:
  - Working EKF implementation
  - Performance baseline
  - Validation against ground truth
"""

# ============================================================================
# SETUP
# ============================================================================

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.linalg import inv
import time

BASE_DIR = '/content/drive/MyDrive/MSIM815'
DATA_DIR = f'{BASE_DIR}/data/large_dataset'
RESULTS_DIR = f'{BASE_DIR}/results/day2'

import os
os.makedirs(RESULTS_DIR, exist_ok=True)

print("‚úÖ Setup complete")

# ============================================================================
# EXTENDED KALMAN FILTER CLASS
# ============================================================================

class ExtendedKalmanFilter:
    """
    Extended Kalman Filter for 3D position tracking

    State: x = [x, y, z, vx, vy, vz]·µÄ  (6D)
    Measurement: z = [x, y, z]·µÄ         (3D position from GPS)
    """

    def __init__(self, dt=0.01, process_noise=0.01, measurement_noise=None):
        """
        Initialize EKF

        Args:
            dt: Time step (seconds)
            process_noise: Process noise parameter
            measurement_noise: Measurement noise covariance (3x3)
        """
        self.dt = dt

        # State vector: [x, y, z, vx, vy, vz]
        self.x = np.zeros(6)

        # State covariance (6x6)
        self.P = np.eye(6) * 1.0

        # State transition matrix F (constant velocity model)
        self.F = np.array([
            [1, 0, 0, dt, 0,  0],
            [0, 1, 0, 0,  dt, 0],
            [0, 0, 1, 0,  0,  dt],
            [0, 0, 0, 1,  0,  0],
            [0, 0, 0, 0,  1,  0],
            [0, 0, 0, 0,  0,  1]
        ])

        # Process noise covariance Q (6x6)
        self.Q = np.eye(6) * process_noise

        # Measurement matrix H (measures position only)
        self.H = np.array([
            [1, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0],
            [0, 0, 1, 0, 0, 0]
        ])

        # Measurement noise covariance R (3x3)
        if measurement_noise is None:
            # Default: GPS noise [œÉx¬≤, œÉy¬≤, œÉz¬≤]
            self.R = np.diag([9.0, 9.0, 25.0])  # [3m, 3m, 5m]
        else:
            self.R = measurement_noise

    def predict(self):
        """
        Prediction step: Estimate state at time k based on k-1
        """
        # State prediction
        self.x = self.F @ self.x

        # Covariance prediction
        self.P = self.F @ self.P @ self.F.T + self.Q

    def update(self, measurement):
        """
        Update step: Correct prediction using measurement

        Args:
            measurement: [x, y, z] position measurement
        """
        # Innovation (measurement residual)
        y = measurement - self.H @ self.x

        # Innovation covariance
        S = self.H @ self.P @ self.H.T + self.R

        # Kalman gain
        K = self.P @ self.H.T @ inv(S)

        # State update
        self.x = self.x + K @ y

        # Covariance update
        I = np.eye(6)
        self.P = (I - K @ self.H) @ self.P

    def get_position(self):
        """Return current position estimate [x, y, z]"""
        return self.x[:3]

    def get_velocity(self):
        """Return current velocity estimate [vx, vy, vz]"""
        return self.x[3:]

    def get_state(self):
        """Return full state [x, y, z, vx, vy, vz]"""
        return self.x.copy()

# ============================================================================
# LOAD DATA
# ============================================================================

print("\nüìÇ Loading data...")

# Load GPS measurements (one channel)
gps_data = pd.read_csv(f'{DATA_DIR}/channel_gps_15min.csv').values
ground_truth_data = pd.read_csv(f'{DATA_DIR}/ground_truth_15min.csv').values

n_samples = len(gps_data)
dt = 0.01  # 100 Hz = 0.01s

print(f"   Loaded {n_samples:,} samples")
print(f"   Time step: {dt}s ({1/dt:.0f} Hz)")

# ============================================================================
# RUN EKF
# ============================================================================

print("\nüîÑ Running EKF...")

# Initialize filter
ekf = ExtendedKalmanFilter(
    dt=dt,
    process_noise=0.01,
    measurement_noise=np.diag([9.0, 9.0, 25.0])
)

# Initialize with first GPS measurement
ekf.x[:3] = gps_data[0]
ekf.x[3:] = [0, 0, 0]  # Zero initial velocity

# Storage for results
ekf_positions = np.zeros((n_samples, 3))
ekf_velocities = np.zeros((n_samples, 3))

# Process each measurement
start_time = time.time()

for i in range(n_samples):
    # Predict
    ekf.predict()

    # Update with GPS measurement
    ekf.update(gps_data[i])

    # Store results
    ekf_positions[i] = ekf.get_position()
    ekf_velocities[i] = ekf.get_velocity()

    # Progress
    if (i + 1) % 10000 == 0:
        print(f"   Processed {i+1:,}/{n_samples:,} samples...")

elapsed_time = time.time() - start_time

print(f"\n‚úÖ EKF complete!")
print(f"   Processing time: {elapsed_time:.3f}s")
print(f"   Samples/second: {n_samples/elapsed_time:,.0f}")

# ============================================================================
# CALCULATE ERRORS
# ============================================================================

print("\nüìä Calculating errors...")

# Extract ground truth position
gt_positions = ground_truth_data[:, :3]

# Calculate errors
gps_errors = np.linalg.norm(gps_data - gt_positions, axis=1)
ekf_errors = np.linalg.norm(ekf_positions - gt_positions, axis=1)

# Statistics
gps_stats = {
    'mean': np.mean(gps_errors),
    'std': np.std(gps_errors),
    'median': np.median(gps_errors),
    'p95': np.percentile(gps_errors, 95),
    'max': np.max(gps_errors)
}

ekf_stats = {
    'mean': np.mean(ekf_errors),
    'std': np.std(ekf_errors),
    'median': np.median(ekf_errors),
    'p95': np.percentile(ekf_errors, 95),
    'max': np.max(ekf_errors)
}

improvement = (1 - ekf_stats['mean'] / gps_stats['mean']) * 100

print("\n" + "="*70)
print("PERFORMANCE SUMMARY")
print("="*70)
print(f"\nRaw GPS Error:")
print(f"   Mean:   {gps_stats['mean']:.4f} m")
print(f"   Std:    {gps_stats['std']:.4f} m")
print(f"   Median: {gps_stats['median']:.4f} m")
print(f"   95th %: {gps_stats['p95']:.4f} m")

print(f"\nEKF Error:")
print(f"   Mean:   {ekf_stats['mean']:.4f} m")
print(f"   Std:    {ekf_stats['std']:.4f} m")
print(f"   Median: {ekf_stats['median']:.4f} m")
print(f"   95th %: {ekf_stats['p95']:.4f} m")

print(f"\n‚≠ê Improvement: {improvement:.2f}%")

# ============================================================================
# VISUALIZE RESULTS
# ============================================================================

print("\nüìä Creating visualizations...")

fig = plt.figure(figsize=(16, 12))

# Plot 1: 3D trajectory comparison
ax1 = fig.add_subplot(2, 3, 1, projection='3d')
subsample = slice(0, n_samples, 100)
ax1.plot(gt_positions[subsample, 0], gt_positions[subsample, 1],
         gt_positions[subsample, 2], 'k-', linewidth=2, label='Ground Truth', alpha=0.7)
ax1.plot(gps_data[subsample, 0], gps_data[subsample, 1],
         gps_data[subsample, 2], 'r.', markersize=2, label='GPS (noisy)', alpha=0.4)
ax1.plot(ekf_positions[subsample, 0], ekf_positions[subsample, 1],
         ekf_positions[subsample, 2], 'b-', linewidth=1.5, label='EKF', alpha=0.8)
ax1.set_xlabel('X (m)')
ax1.set_ylabel('Y (m)')
ax1.set_zlabel('Z (m)')
ax1.set_title('3D Trajectory Comparison', fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Error comparison (time series)
ax2 = fig.add_subplot(2, 3, 2)
time_axis = np.arange(n_samples) * dt / 60  # minutes
window = slice(0, min(6000, n_samples))  # First minute
ax2.plot(time_axis[window], gps_errors[window], 'r-', alpha=0.6, linewidth=1, label='GPS Error')
ax2.plot(time_axis[window], ekf_errors[window], 'b-', linewidth=1.5, label='EKF Error')
ax2.set_xlabel('Time (minutes)')
ax2.set_ylabel('Position Error (m)')
ax2.set_title('Error Over Time (First Minute)', fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Plot 3: Error histogram
ax3 = fig.add_subplot(2, 3, 3)
bins = np.linspace(0, max(gps_errors.max(), ekf_errors.max()), 50)
ax3.hist(gps_errors, bins=bins, alpha=0.6, color='red', label='GPS', density=True)
ax3.hist(ekf_errors, bins=bins, alpha=0.6, color='blue', label='EKF', density=True)
ax3.axvline(gps_stats['mean'], color='red', linestyle='--', linewidth=2, label='GPS Mean')
ax3.axvline(ekf_stats['mean'], color='blue', linestyle='--', linewidth=2, label='EKF Mean')
ax3.set_xlabel('Position Error (m)')
ax3.set_ylabel('Density')
ax3.set_title('Error Distribution', fontweight='bold')
ax3.legend()
ax3.grid(True, alpha=0.3)

# Plot 4: CDF comparison
ax4 = fig.add_subplot(2, 3, 4)
sorted_gps = np.sort(gps_errors)
sorted_ekf = np.sort(ekf_errors)
cdf = np.arange(1, len(sorted_gps)+1) / len(sorted_gps)
ax4.plot(sorted_gps, cdf, 'r-', linewidth=2, label='GPS')
ax4.plot(sorted_ekf, cdf, 'b-', linewidth=2, label='EKF')
ax4.axhline(0.95, color='gray', linestyle='--', alpha=0.5)
ax4.text(ax4.get_xlim()[1]*0.6, 0.96, '95th percentile', fontsize=10)
ax4.set_xlabel('Position Error (m)')
ax4.set_ylabel('Cumulative Probability')
ax4.set_title('Cumulative Distribution Function', fontweight='bold')
ax4.legend()
ax4.grid(True, alpha=0.3)

# Plot 5: X, Y, Z error breakdown
ax5 = fig.add_subplot(2, 3, 5)
gps_errors_xyz = gps_data - gt_positions
ekf_errors_xyz = ekf_positions - gt_positions

dims = ['X', 'Y', 'Z']
gps_rmse = [np.sqrt(np.mean(gps_errors_xyz[:, i]**2)) for i in range(3)]
ekf_rmse = [np.sqrt(np.mean(ekf_errors_xyz[:, i]**2)) for i in range(3)]

x_pos = np.arange(len(dims))
width = 0.35
ax5.bar(x_pos - width/2, gps_rmse, width, label='GPS', color='red', alpha=0.7)
ax5.bar(x_pos + width/2, ekf_rmse, width, label='EKF', color='blue', alpha=0.7)
ax5.set_ylabel('RMSE (m)')
ax5.set_title('Error by Dimension', fontweight='bold')
ax5.set_xticks(x_pos)
ax5.set_xticklabels(dims)
ax5.legend()
ax5.grid(True, alpha=0.3, axis='y')

# Plot 6: Statistics table
ax6 = fig.add_subplot(2, 3, 6)
ax6.axis('off')

stats_text = f"""
EKF PERFORMANCE SUMMARY
{'='*50}

Raw GPS:
  Mean Error:    {gps_stats['mean']:.4f} m
  Std Dev:       {gps_stats['std']:.4f} m
  Median:        {gps_stats['median']:.4f} m
  95th %ile:     {gps_stats['p95']:.4f} m

EKF Filtered:
  Mean Error:    {ekf_stats['mean']:.4f} m
  Std Dev:       {ekf_stats['std']:.4f} m
  Median:        {ekf_stats['median']:.4f} m
  95th %ile:     {ekf_stats['p95']:.4f} m

Improvement:     {improvement:.2f}%

Processing:
  Time:          {elapsed_time:.3f} seconds
  Rate:          {n_samples/elapsed_time:,.0f} samples/sec
  Samples:       {n_samples:,}

Configuration:
  dt:            {dt}s ({1/dt:.0f} Hz)
  State dim:     6 (position + velocity)
  Process noise: 0.01
  GPS noise:     œÉ=[3, 3, 5]m
"""

ax6.text(0.1, 0.5, stats_text, fontsize=10, family='monospace',
        verticalalignment='center')

plt.suptitle('Day 2: Python EKF Implementation Results', fontsize=16, fontweight='bold')
plt.tight_layout()

viz_path = f'{RESULTS_DIR}/day2_ekf_results.png'
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
plt.show()

print(f"   ‚úÖ Visualization saved: {viz_path}")

# ============================================================================
# SAVE RESULTS
# ============================================================================

print("\nüíæ Saving results...")

# Save EKF outputs
ekf_df = pd.DataFrame(ekf_positions, columns=['x', 'y', 'z'])
ekf_path = f'{RESULTS_DIR}/ekf_outputs.csv'
ekf_df.to_csv(ekf_path, index=False)
print(f"   ‚úÖ EKF outputs: {ekf_path}")

# Save statistics
import json
results = {
    'gps_stats': gps_stats,
    'ekf_stats': ekf_stats,
    'improvement_pct': improvement,
    'processing_time_sec': elapsed_time,
    'samples_per_sec': n_samples / elapsed_time,
    'config': {
        'dt': dt,
        'process_noise': 0.01,
        'measurement_noise': [9.0, 9.0, 25.0]
    }
}

results_path = f'{RESULTS_DIR}/day2_results.json'
with open(results_path, 'w') as f:
    json.dump(results, f, indent=2)
print(f"   ‚úÖ Results JSON: {results_path}")

# ============================================================================
# SUMMARY
# ============================================================================

print("\n" + "="*70)
print("‚úÖ DAY 2 COMPLETE")
print("="*70)
print(f"\nKey Results:")
print(f"  ‚≠ê EKF reduces error by {improvement:.1f}%")
print(f"  üìâ GPS: {gps_stats['mean']:.3f}m ‚Üí EKF: {ekf_stats['mean']:.3f}m")
print(f"  ‚ö° Processing: {n_samples/elapsed_time:,.0f} samples/sec")
print(f"\nReady for Day 3: C++ conversion + OpenMP parallelization")
print("="*70)